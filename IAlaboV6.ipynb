{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "287c2e3e-9842-4742-af1b-5b07d12d2e3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
      "    â•‘                                                                  â•‘\n",
      "    â•‘          ğŸ§  IA LABO - VARIANTE 1 (RÃ‰SEAU DE NEURONES) ğŸ§          â•‘\n",
      "    â•‘                    EntrÃ©es PondÃ©rÃ©es + SGD                       â•‘\n",
      "    â•‘                                                                  â•‘\n",
      "    â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "    \n",
      "âœ… 960 tirages chargÃ©s pour Loto\n",
      "\n",
      "======================================================================\n",
      "                  ğŸ”¬ IA LABO - ANALYSE MULTI-MODÃˆLES                   \n",
      "                              Jeu: Loto                               \n",
      "======================================================================\n",
      "\n",
      "âš™ï¸  Calcul des scores par module...\n",
      "   âœ“ FrÃ©quence\n",
      "   âœ“ Markov\n",
      "   âœ“ Ã‰carts\n",
      "   âœ“ NeuralNet_SGD (loss finale: 0.426809)\n",
      "\n",
      "ğŸ“Š TOP 10 PAR MODULE:\n",
      "----------------------------------------------------------------------\n",
      "   FrÃ©quence       â†’ [31, 6, 15, 3, 24, 26, 22, 28, 7, 30]\n",
      "   Markov          â†’ [15, 3, 26, 17, 6, 4, 30, 31, 44, 7]\n",
      "   Ã‰carts          â†’ [47, 21, 46, 45, 20, 32, 36, 5, 3, 1]\n",
      "   NeuralNet_SGD   â†’ [17, 40, 3, 31, 9, 27, 46, 18, 1, 48]\n",
      "\n",
      "======================================================================\n",
      "           ğŸ§  ANALYSE RÃ‰SEAU DE NEURONES (VARIANTE 1 - SGD)            \n",
      "======================================================================\n",
      "\n",
      "ğŸ“Š COEFFICIENTS DES FEATURES:\n",
      "   â€¢ DonnÃ©es historiques (coef1): 0.2\n",
      "   â€¢ FrÃ©quence relative (coef2):  0.25\n",
      "   â€¢ DÃ©jÃ  vu / Ã‰cart (coef3):     0.2\n",
      "   â€¢ Moyenne mobile (coef4):      0.15\n",
      "   â€¢ Entropie (coef5):            0.2\n",
      "\n",
      "ğŸ—ï¸  ARCHITECTURE DU RÃ‰SEAU:\n",
      "   â€¢ Couche d'entrÃ©e:  49 neurones\n",
      "   â€¢ Couche cachÃ©e 1: 128 neurones\n",
      "   â€¢ Couche cachÃ©e 2: 64 neurones\n",
      "   â€¢ Couche de sortie: 49 neurones\n",
      "\n",
      "ğŸ¯ TOP 20 PRÃ‰DICTIONS DU RÃ‰SEAU DE NEURONES:\n",
      "   [17, 40, 3, 31, 9, 27, 46, 18, 1, 48, 11, 22, 38, 19, 5, 26, 14, 36, 12, 7]\n",
      "\n",
      "ğŸ“ˆ SCORES DÃ‰TAILLÃ‰S (Top 10):\n",
      "   NÂ°17: 0.4963 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "   NÂ°40: 0.4711 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "   NÂ° 3: 0.4427 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "   NÂ°31: 0.4417 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "   NÂ° 9: 0.4404 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "   NÂ°27: 0.4286 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "   NÂ°46: 0.4263 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "   NÂ°18: 0.4241 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "   NÂ° 1: 0.4121 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "   NÂ°48: 0.4118 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\n",
      "======================================================================\n",
      "ğŸ“¦ RÃ‰SULTATS AGRÃ‰GÃ‰S\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "   BAGGING (moyenne):    [46, 47, 3, 5, 17, 31, 21, 45, 36, 15, 7, 38, 32, 9, 26]\n",
      "   BOOSTING (pondÃ©rÃ©):   [46, 47, 3, 5, 17, 31, 21, 45, 36, 15, 7, 38, 32, 9, 26]\n",
      "\n",
      "======================================================================\n",
      "ğŸ° COMBINAISONS SUGGÃ‰RÃ‰ES\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "âš™ï¸  Calcul des scores par module...\n",
      "   âœ“ FrÃ©quence\n",
      "   âœ“ Markov\n",
      "   âœ“ Ã‰carts\n",
      "   âœ“ NeuralNet_SGD (loss finale: 0.457812)\n",
      "   Grille 1: [3, 5, 21, 46, 47] (somme: 122)\n",
      "   Grille 2: [6, 21, 26, 28, 46] (somme: 127)\n",
      "   Grille 3: [3, 6, 11, 21, 31] (somme: 72)\n",
      "   Grille 4: [4, 12, 32, 44, 46] (somme: 138)\n",
      "   Grille 5: [4, 8, 13, 24, 38] (somme: 87)\n",
      "\n",
      "======================================================================\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Dict, Tuple\n",
    "from itertools import combinations\n",
    "from abc import ABC, abstractmethod\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ============================================================\n",
    "#                    CONFIGURATION\n",
    "# ============================================================\n",
    "\n",
    "@dataclass\n",
    "class GameConfig:\n",
    "    \"\"\"Configuration pour diffÃ©rents jeux.\"\"\"\n",
    "    name: str\n",
    "    num_max: int\n",
    "    nums_per_draw: int\n",
    "    filepath: str\n",
    "\n",
    "CONFIGS = {\n",
    "    \"loto\": GameConfig(\"Loto\", 49, 5, \"lotodata.csv\"),\n",
    "    \"keno\": GameConfig(\"Keno\", 70, 20, \"kenodata.csv\"),\n",
    "    \"euromillions\": GameConfig(\"EuroMillions\", 50, 5, \"euromillions.csv\"),\n",
    "}\n",
    "\n",
    "# ============================================================\n",
    "#              FONCTIONS D'ACTIVATION\n",
    "# ============================================================\n",
    "\n",
    "def sigmoid(x):\n",
    "    \"\"\"Fonction sigmoid avec protection contre overflow.\"\"\"\n",
    "    x = np.clip(x, -500, 500)\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    \"\"\"DÃ©rivÃ©e de la fonction sigmoid.\"\"\"\n",
    "    return x * (1 - x)\n",
    "\n",
    "def softmax(x):\n",
    "    \"\"\"Fonction softmax stable numÃ©riquement.\"\"\"\n",
    "    exp_x = np.exp(x - np.max(x))\n",
    "    return exp_x / exp_x.sum()\n",
    "\n",
    "# ============================================================\n",
    "#     MODULE RÃ‰SEAU DE NEURONES (VARIANTE 1 - SGD)\n",
    "# ============================================================\n",
    "\n",
    "class NeuralNetworkSGD:\n",
    "       \n",
    "    def __init__(self, \n",
    "                 input_size: int = 70,\n",
    "                 hidden_layers: List[int] = [128, 64],\n",
    "                 output_size: int = 70,\n",
    "                 learning_rate: float = 0.001):\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.hidden_layers = hidden_layers\n",
    "        self.output_size = output_size\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "        # Initialisation des poids et biais\n",
    "        self.weights = []\n",
    "        self.biases = []\n",
    "        \n",
    "        layer_sizes = [input_size] + hidden_layers + [output_size]\n",
    "        \n",
    "        for i in range(len(layer_sizes) - 1):\n",
    "            # Initialisation Xavier/Glorot\n",
    "            limit = np.sqrt(6 / (layer_sizes[i] + layer_sizes[i+1]))\n",
    "            w = np.random.uniform(-limit, limit, (layer_sizes[i], layer_sizes[i+1]))\n",
    "            b = np.zeros((1, layer_sizes[i+1]))\n",
    "            self.weights.append(w)\n",
    "            self.biases.append(b)\n",
    "        \n",
    "        # Stockage des activations pour la rÃ©tropropagation\n",
    "        self.activations = []\n",
    "        self.z_values = []\n",
    "        \n",
    "    def forward(self, X: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Propagation avant.\"\"\"\n",
    "        self.activations = [X]\n",
    "        self.z_values = []\n",
    "        \n",
    "        current = X\n",
    "        for i, (w, b) in enumerate(zip(self.weights, self.biases)):\n",
    "            z = np.dot(current, w) + b\n",
    "            self.z_values.append(z)\n",
    "            \n",
    "            if i == len(self.weights) - 1:\n",
    "                # DerniÃ¨re couche: sigmoid pour probabilitÃ©s\n",
    "                current = sigmoid(z)\n",
    "            else:\n",
    "                # Couches cachÃ©es: sigmoid\n",
    "                current = sigmoid(z)\n",
    "            \n",
    "            self.activations.append(current)\n",
    "        \n",
    "        return current\n",
    "    \n",
    "    def backward(self, y_true: np.ndarray, epsilon: float = 1e-7):\n",
    "        \"\"\"\n",
    "        RÃ©tropropagation avec SGD.\n",
    "        ImplÃ©mente la logique de Retropropagation_sgd du code FreeBasic.\n",
    "        \"\"\"\n",
    "        m = y_true.shape[0] if len(y_true.shape) > 1 else 1\n",
    "        y_pred = self.activations[-1]\n",
    "        \n",
    "        # Erreur de la couche de sortie (cross-entropy derivative)\n",
    "        # erreurSortie = -cibles/sortie + (1-cibles)/(1-sortie)\n",
    "        delta = (-y_true / (y_pred + epsilon) + (1 - y_true) / (1 - y_pred + epsilon))\n",
    "        delta = delta * sigmoid_derivative(y_pred)\n",
    "        \n",
    "        deltas = [delta]\n",
    "        \n",
    "        # RÃ©tropropagation Ã  travers les couches cachÃ©es\n",
    "        for i in range(len(self.weights) - 2, -1, -1):\n",
    "            delta = np.dot(deltas[-1], self.weights[i + 1].T)\n",
    "            delta = delta * sigmoid_derivative(self.activations[i + 1])\n",
    "            deltas.append(delta)\n",
    "        \n",
    "        deltas.reverse()\n",
    "        \n",
    "        # Mise Ã  jour des poids et biais\n",
    "        for i in range(len(self.weights)):\n",
    "            activation = self.activations[i]\n",
    "            if len(activation.shape) == 1:\n",
    "                activation = activation.reshape(1, -1)\n",
    "            if len(deltas[i].shape) == 1:\n",
    "                deltas[i] = deltas[i].reshape(1, -1)\n",
    "                \n",
    "            self.weights[i] -= self.learning_rate * np.dot(activation.T, deltas[i]) / m\n",
    "            self.biases[i] -= self.learning_rate * np.mean(deltas[i], axis=0, keepdims=True)\n",
    "    \n",
    "    def compute_loss(self, y_true: np.ndarray, y_pred: np.ndarray, epsilon: float = 1e-7) -> float:\n",
    "        \"\"\"\n",
    "        Calcul de la perte (cross-entropy binaire).\n",
    "        perte = -cibles * log(sortie) - (1-cibles) * log(1-sortie)\n",
    "        \"\"\"\n",
    "        y_pred = np.clip(y_pred, epsilon, 1 - epsilon)\n",
    "        loss = -np.mean(y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred))\n",
    "        return loss\n",
    "    \n",
    "    def train(self, X: np.ndarray, y: np.ndarray, epochs: int = 100, verbose: bool = False):\n",
    "        \"\"\"EntraÃ®nement du rÃ©seau.\"\"\"\n",
    "        losses = []\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            # Propagation avant\n",
    "            y_pred = self.forward(X)\n",
    "            \n",
    "            # Calcul de la perte\n",
    "            loss = self.compute_loss(y, y_pred)\n",
    "            losses.append(loss)\n",
    "            \n",
    "            # RÃ©tropropagation\n",
    "            self.backward(y)\n",
    "            \n",
    "            if verbose and (epoch + 1) % 10 == 0:\n",
    "                print(f\"   Epoch {epoch+1}/{epochs} - Loss: {loss:.6f}\")\n",
    "        \n",
    "        return losses\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "#     CALCULATEUR DE FEATURES (VARIANTE 1)\n",
    "# ============================================================\n",
    "\n",
    "class FeatureCalculator:\n",
    "    \"\"\"\n",
    "    Calcule les features d'entrÃ©e pour le rÃ©seau de neurones.\n",
    "    Traduit depuis le code FreeBasic.\n",
    "    \n",
    "    Features:\n",
    "    1. DonnÃ©es historiques normalisÃ©es\n",
    "    2. FrÃ©quence relative des numÃ©ros\n",
    "    3. \"DÃ©jÃ  vu\" (Ã©cart depuis derniÃ¨re apparition)\n",
    "    4. Moyennes mobiles\n",
    "    5. Entropie des numÃ©ros\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, config: GameConfig, \n",
    "                 coef1: float = 0.2,  # DonnÃ©es historiques\n",
    "                 coef2: float = 0.25, # FrÃ©quence relative\n",
    "                 coef3: float = 0.2,  # DÃ©jÃ  vu\n",
    "                 coef4: float = 0.15, # Moyenne mobile\n",
    "                 coef5: float = 0.2): # Entropie\n",
    "        \n",
    "        self.config = config\n",
    "        self.coef1 = coef1\n",
    "        self.coef2 = coef2\n",
    "        self.coef3 = coef3\n",
    "        self.coef4 = coef4\n",
    "        self.coef5 = coef5\n",
    "        \n",
    "    def compute_frequency(self, historique: List[List[int]]) -> np.ndarray:\n",
    "        \"\"\"Calcule la frÃ©quence relative de chaque numÃ©ro.\"\"\"\n",
    "        freq = np.zeros(self.config.num_max)\n",
    "        total = 0\n",
    "        \n",
    "        for draw in historique:\n",
    "            for num in draw:\n",
    "                if 1 <= num <= self.config.num_max:\n",
    "                    freq[num - 1] += 1\n",
    "                    total += 1\n",
    "        \n",
    "        if total > 0:\n",
    "            freq = freq / total\n",
    "        \n",
    "        return freq\n",
    "    \n",
    "    def compute_dejavu(self, historique: List[List[int]]) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Calcule le 'dÃ©jÃ  vu' - nombre de tirages depuis la derniÃ¨re apparition.\n",
    "        Plus la valeur est Ã©levÃ©e, plus le numÃ©ro est \"en retard\".\n",
    "        \"\"\"\n",
    "        dejavu = np.zeros((len(historique), self.config.num_max))\n",
    "        \n",
    "        for tirage_idx in range(len(historique)):\n",
    "            if tirage_idx > 0:\n",
    "                # IncrÃ©menter tous les dÃ©jÃ  vu\n",
    "                dejavu[tirage_idx] = dejavu[tirage_idx - 1] + 1\n",
    "            \n",
    "            # RÃ©initialiser pour les numÃ©ros tirÃ©s\n",
    "            for num in historique[tirage_idx]:\n",
    "                if 1 <= num <= self.config.num_max:\n",
    "                    dejavu[tirage_idx, num - 1] = 0\n",
    "        \n",
    "        return dejavu\n",
    "    \n",
    "    def compute_moving_average(self, historique: List[List[int]], window: int = 10) -> np.ndarray:\n",
    "        \"\"\"Calcule la moyenne mobile des apparitions.\"\"\"\n",
    "        n_tirages = len(historique)\n",
    "        ma = np.zeros((n_tirages, self.config.num_max))\n",
    "        \n",
    "        # CrÃ©er une matrice binaire d'apparition\n",
    "        presence = np.zeros((n_tirages, self.config.num_max))\n",
    "        for i, draw in enumerate(historique):\n",
    "            for num in draw:\n",
    "                if 1 <= num <= self.config.num_max:\n",
    "                    presence[i, num - 1] = 1\n",
    "        \n",
    "        # Calculer la moyenne mobile\n",
    "        for i in range(n_tirages):\n",
    "            start = max(0, i - window + 1)\n",
    "            ma[i] = np.mean(presence[start:i+1], axis=0)\n",
    "        \n",
    "        return ma\n",
    "    \n",
    "    def compute_entropy(self, historique: List[List[int]]) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Calcule l'entropie pour chaque numÃ©ro.\n",
    "        entropie = -p * log(p) oÃ¹ p est la probabilitÃ© d'apparition.\n",
    "        \"\"\"\n",
    "        freq = self.compute_frequency(historique)\n",
    "        entropy = np.zeros(self.config.num_max)\n",
    "        \n",
    "        for i in range(self.config.num_max):\n",
    "            if freq[i] > 0:\n",
    "                entropy[i] = -freq[i] * np.log(freq[i] + 1e-10)\n",
    "        \n",
    "        return entropy\n",
    "    \n",
    "    def compute_all_features(self, historique: List[List[int]]) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        \"\"\"\n",
    "        Calcule toutes les features et retourne les entrÃ©es et cibles.\n",
    "        \n",
    "        Returns:\n",
    "            X: Matrice des entrÃ©es (n_tirages, num_max)\n",
    "            y: Matrice des cibles (n_tirages, num_max)\n",
    "        \"\"\"\n",
    "        n_tirages = len(historique)\n",
    "        \n",
    "        # Calculer chaque feature\n",
    "        freq_relative = self.compute_frequency(historique)\n",
    "        dejavu = self.compute_dejavu(historique)\n",
    "        moving_avg = self.compute_moving_average(historique)\n",
    "        entropy = self.compute_entropy(historique)\n",
    "        \n",
    "        # Normalisation de l'entropie\n",
    "        entropy_max = np.max(entropy) if np.max(entropy) > 0 else 1\n",
    "        entropy_norm = entropy / entropy_max\n",
    "        \n",
    "        # Construire la matrice d'entrÃ©e\n",
    "        X = np.zeros((n_tirages, self.config.num_max))\n",
    "        y = np.zeros((n_tirages, self.config.num_max))\n",
    "        \n",
    "        # Matrice binaire des tirages (pour coef1)\n",
    "        presence = np.zeros((n_tirages, self.config.num_max))\n",
    "        for i, draw in enumerate(historique):\n",
    "            for num in draw:\n",
    "                if 1 <= num <= self.config.num_max:\n",
    "                    presence[i, num - 1] = 1\n",
    "        \n",
    "        for tirage in range(n_tirages):\n",
    "            for num in range(self.config.num_max):\n",
    "                # Combinaison linÃ©aire des features (comme dans le code FreeBasic)\n",
    "                val = (self.coef1 * presence[tirage, num] +\n",
    "                       self.coef2 * freq_relative[num] +\n",
    "                       self.coef3 * (dejavu[tirage, num] / 15.0) +  # Normalisation par 15\n",
    "                       self.coef4 * moving_avg[tirage, num] +\n",
    "                       self.coef5 * entropy_norm[num])\n",
    "                \n",
    "                # Contraindre entre 0 et 0.99\n",
    "                X[tirage, num] = np.clip(val, 0, 0.99)\n",
    "        \n",
    "        # Calculer les cibles (frÃ©quence cumulative normalisÃ©e)\n",
    "        freq_cumul = np.zeros((n_tirages, self.config.num_max))\n",
    "        for tirage in range(n_tirages):\n",
    "            for draw in historique[:tirage+1]:\n",
    "                for num in draw:\n",
    "                    if 1 <= num <= self.config.num_max:\n",
    "                        freq_cumul[tirage, num - 1] += 1\n",
    "            \n",
    "            total = np.sum(freq_cumul[tirage])\n",
    "            if total > 0:\n",
    "                y[tirage] = np.clip(freq_cumul[tirage] / total, 0, 0.99)\n",
    "        \n",
    "        return X, y\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "#     MODULE NEURAL NETWORK POUR IA LABO\n",
    "# ============================================================\n",
    "\n",
    "class PredictionModule(ABC):\n",
    "    \"\"\"Interface commune pour tous les modules de prÃ©diction.\"\"\"\n",
    "    \n",
    "    def __init__(self, name: str, config: GameConfig):\n",
    "        self.name = name\n",
    "        self.config = config\n",
    "        self.historique: List[List[int]] = []\n",
    "        self.scores: Dict[int, float] = {}\n",
    "        self.confidence: float = 1.0\n",
    "        \n",
    "    @abstractmethod\n",
    "    def compute_scores(self) -> Dict[int, float]:\n",
    "        pass\n",
    "    \n",
    "    def get_top_numbers(self, n: int) -> List[int]:\n",
    "        sorted_nums = sorted(self.scores.items(), key=lambda x: x[1], reverse=True)\n",
    "        return [num for num, score in sorted_nums[:n]]\n",
    "\n",
    "\n",
    "class NeuralNetworkModule(PredictionModule):\n",
    "    \"\"\"\n",
    "    Module de rÃ©seau de neurones avec entrÃ©es pondÃ©rÃ©es (Variante 1).\n",
    "    Utilise SGD pour l'optimisation.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, config: GameConfig,\n",
    "                 hidden_layers: List[int] = [128, 64],\n",
    "                 epochs: int = 50,\n",
    "                 learning_rate: float = 0.001,\n",
    "                 coefficients: Tuple[float, ...] = (0.2, 0.25, 0.2, 0.15, 0.2)):\n",
    "        \n",
    "        super().__init__(\"NeuralNet_SGD\", config)\n",
    "        \n",
    "        self.hidden_layers = hidden_layers\n",
    "        self.epochs = epochs\n",
    "        self.learning_rate = learning_rate\n",
    "        self.coefficients = coefficients\n",
    "        \n",
    "        # Initialiser le calculateur de features\n",
    "        self.feature_calc = FeatureCalculator(\n",
    "            config,\n",
    "            coef1=coefficients[0],\n",
    "            coef2=coefficients[1],\n",
    "            coef3=coefficients[2],\n",
    "            coef4=coefficients[3],\n",
    "            coef5=coefficients[4]\n",
    "        )\n",
    "        \n",
    "        # Le rÃ©seau sera initialisÃ© lors du calcul des scores\n",
    "        self.network = None\n",
    "        self.training_losses = []\n",
    "        \n",
    "    def compute_scores(self) -> Dict[int, float]:\n",
    "        \"\"\"EntraÃ®ne le rÃ©seau et calcule les scores de sortie.\"\"\"\n",
    "        if len(self.historique) < 10:\n",
    "            print(f\"   âš ï¸  {self.name}: Pas assez de donnÃ©es pour l'entraÃ®nement\")\n",
    "            return {i: 0.5 for i in range(1, self.config.num_max + 1)}\n",
    "        \n",
    "        # Calculer les features\n",
    "        X, y = self.feature_calc.compute_all_features(self.historique)\n",
    "        \n",
    "        # Initialiser le rÃ©seau\n",
    "        self.network = NeuralNetworkSGD(\n",
    "            input_size=self.config.num_max,\n",
    "            hidden_layers=self.hidden_layers,\n",
    "            output_size=self.config.num_max,\n",
    "            learning_rate=self.learning_rate\n",
    "        )\n",
    "        \n",
    "        # EntraÃ®ner le rÃ©seau\n",
    "        self.training_losses = self.network.train(X, y, epochs=self.epochs, verbose=False)\n",
    "        \n",
    "        # PrÃ©diction finale (utiliser les derniÃ¨res donnÃ©es)\n",
    "        last_features = X[-1:, :]\n",
    "        predictions = self.network.forward(last_features)\n",
    "        \n",
    "        # Convertir en scores\n",
    "        output = predictions.flatten()\n",
    "        for i in range(self.config.num_max):\n",
    "            self.scores[i + 1] = float(output[i])\n",
    "        \n",
    "        return self.scores\n",
    "    \n",
    "    def get_training_loss(self) -> float:\n",
    "        \"\"\"Retourne la derniÃ¨re perte d'entraÃ®nement.\"\"\"\n",
    "        if self.training_losses:\n",
    "            return self.training_losses[-1]\n",
    "        return float('inf')\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "#              AUTRES MODULES (simplifiÃ©s)\n",
    "# ============================================================\n",
    "\n",
    "class FrequencyModule(PredictionModule):\n",
    "    \"\"\"Module basÃ© sur les frÃ©quences.\"\"\"\n",
    "    \n",
    "    def __init__(self, config: GameConfig):\n",
    "        super().__init__(\"FrÃ©quence\", config)\n",
    "        \n",
    "    def compute_scores(self) -> Dict[int, float]:\n",
    "        if not self.historique:\n",
    "            return {i: 0.0 for i in range(1, self.config.num_max + 1)}\n",
    "        \n",
    "        all_nums = [n for draw in self.historique for n in draw]\n",
    "        freq = Counter(all_nums)\n",
    "        \n",
    "        max_freq = max(freq.values()) if freq else 1\n",
    "        for i in range(1, self.config.num_max + 1):\n",
    "            self.scores[i] = freq.get(i, 0) / max_freq\n",
    "            \n",
    "        return self.scores\n",
    "\n",
    "\n",
    "class GapModule(PredictionModule):\n",
    "    \"\"\"Module basÃ© sur les Ã©carts.\"\"\"\n",
    "    \n",
    "    def __init__(self, config: GameConfig):\n",
    "        super().__init__(\"Ã‰carts\", config)\n",
    "        \n",
    "    def compute_scores(self) -> Dict[int, float]:\n",
    "        if not self.historique:\n",
    "            return {i: 0.0 for i in range(1, self.config.num_max + 1)}\n",
    "        \n",
    "        last_seen = {i: -1 for i in range(1, self.config.num_max + 1)}\n",
    "        \n",
    "        for idx, draw in enumerate(self.historique):\n",
    "            for num in draw:\n",
    "                last_seen[num] = idx\n",
    "        \n",
    "        last_idx = len(self.historique) - 1\n",
    "        gaps = {}\n",
    "        for num, seen_idx in last_seen.items():\n",
    "            gaps[num] = (last_idx - seen_idx) if seen_idx != -1 else len(self.historique)\n",
    "        \n",
    "        max_gap = max(gaps.values()) if gaps else 1\n",
    "        for num, gap in gaps.items():\n",
    "            self.scores[num] = gap / max_gap\n",
    "            \n",
    "        return self.scores\n",
    "\n",
    "\n",
    "class MarkovModule(PredictionModule):\n",
    "    \"\"\"Module basÃ© sur les chaÃ®nes de Markov.\"\"\"\n",
    "    \n",
    "    def __init__(self, config: GameConfig):\n",
    "        super().__init__(\"Markov\", config)\n",
    "        \n",
    "    def compute_scores(self) -> Dict[int, float]:\n",
    "        if len(self.historique) < 2:\n",
    "            return {i: 0.0 for i in range(1, self.config.num_max + 1)}\n",
    "        \n",
    "        # Matrice de transition\n",
    "        transitions = Counter()\n",
    "        for i in range(len(self.historique) - 1):\n",
    "            for num in self.historique[i]:\n",
    "                for next_num in self.historique[i + 1]:\n",
    "                    transitions[(num, next_num)] += 1\n",
    "        \n",
    "        # Scores basÃ©s sur le dernier tirage\n",
    "        last_draw = self.historique[-1]\n",
    "        transition_scores = Counter()\n",
    "        \n",
    "        for num in last_draw:\n",
    "            for (from_num, to_num), count in transitions.items():\n",
    "                if from_num == num:\n",
    "                    transition_scores[to_num] += count\n",
    "        \n",
    "        max_score = max(transition_scores.values()) if transition_scores else 1\n",
    "        for i in range(1, self.config.num_max + 1):\n",
    "            self.scores[i] = transition_scores.get(i, 0) / max_score\n",
    "            \n",
    "        return self.scores\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "#              AGRÃ‰GATEUR PRINCIPAL (IA LABO)\n",
    "# ============================================================\n",
    "\n",
    "class IALabo:\n",
    "    \"\"\"\n",
    "    SystÃ¨me d'agrÃ©gation multi-modÃ¨les avec rÃ©seau de neurones.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, config: GameConfig):\n",
    "        self.config = config\n",
    "        self.historique: List[List[int]] = []\n",
    "        \n",
    "        # Initialiser les modules (incluant le nouveau NeuralNetwork)\n",
    "        self.modules: List[PredictionModule] = [\n",
    "            FrequencyModule(config),\n",
    "            MarkovModule(config),\n",
    "            GapModule(config),\n",
    "            NeuralNetworkModule(config, \n",
    "                               hidden_layers=[128, 64],\n",
    "                               epochs=100,\n",
    "                               learning_rate=0.001),\n",
    "        ]\n",
    "        \n",
    "        self.weights: Dict[str, float] = {m.name: 1.0 for m in self.modules}\n",
    "        self._load_data()\n",
    "        \n",
    "    def _load_data(self):\n",
    "        \"\"\"Charge les donnÃ©es historiques.\"\"\"\n",
    "        try:\n",
    "            df = pd.read_csv(self.config.filepath, sep=';')\n",
    "            num_cols = [col for col in df.columns if col.startswith('num')][:self.config.nums_per_draw]\n",
    "            if not num_cols:\n",
    "                num_cols = df.select_dtypes(include=[np.number]).columns[:self.config.nums_per_draw].tolist()\n",
    "            \n",
    "            self.historique = df[num_cols].dropna().apply(\n",
    "                lambda x: sorted([int(v) for v in x.tolist()]), axis=1\n",
    "            ).tolist()\n",
    "            \n",
    "            for module in self.modules:\n",
    "                module.historique = self.historique\n",
    "                \n",
    "            print(f\"âœ… {len(self.historique)} tirages chargÃ©s pour {self.config.name}\")\n",
    "            \n",
    "        except FileNotFoundError:\n",
    "            print(f\"âš ï¸  Fichier '{self.config.filepath}' introuvable. Mode dÃ©mo activÃ©.\")\n",
    "            import random\n",
    "            self.historique = [\n",
    "                sorted(random.sample(range(1, self.config.num_max + 1), self.config.nums_per_draw))\n",
    "                for _ in range(500)\n",
    "            ]\n",
    "            for module in self.modules:\n",
    "                module.historique = self.historique\n",
    "                \n",
    "    def _compute_all_scores(self):\n",
    "        \"\"\"Calcule les scores de tous les modules.\"\"\"\n",
    "        print(\"\\nâš™ï¸  Calcul des scores par module...\")\n",
    "        for module in self.modules:\n",
    "            module.compute_scores()\n",
    "            if isinstance(module, NeuralNetworkModule):\n",
    "                loss = module.get_training_loss()\n",
    "                print(f\"   âœ“ {module.name} (loss finale: {loss:.6f})\")\n",
    "            else:\n",
    "                print(f\"   âœ“ {module.name}\")\n",
    "            \n",
    "    def aggregate_bagging(self) -> Dict[int, float]:\n",
    "        \"\"\"BAGGING: Moyenne simple des scores.\"\"\"\n",
    "        aggregated = {i: 0.0 for i in range(1, self.config.num_max + 1)}\n",
    "        \n",
    "        for num in aggregated:\n",
    "            total = sum(module.scores.get(num, 0) for module in self.modules)\n",
    "            aggregated[num] = total / len(self.modules)\n",
    "            \n",
    "        return aggregated\n",
    "    \n",
    "    def aggregate_boosting(self) -> Dict[int, float]:\n",
    "        \"\"\"BOOSTING: Moyenne pondÃ©rÃ©e.\"\"\"\n",
    "        aggregated = {i: 0.0 for i in range(1, self.config.num_max + 1)}\n",
    "        total_weight = sum(self.weights.values())\n",
    "        \n",
    "        for num in aggregated:\n",
    "            weighted_sum = sum(\n",
    "                module.scores.get(num, 0) * self.weights[module.name]\n",
    "                for module in self.modules\n",
    "            )\n",
    "            aggregated[num] = weighted_sum / total_weight\n",
    "            \n",
    "        return aggregated\n",
    "    \n",
    "    def generate_combinations(self, n: int = 5, method: str = \"boosting\") -> List[List[int]]:\n",
    "        \"\"\"GÃ©nÃ¨re n combinaisons.\"\"\"\n",
    "        self._compute_all_scores()\n",
    "        \n",
    "        if method == \"bagging\":\n",
    "            final_scores = self.aggregate_bagging()\n",
    "        else:\n",
    "            final_scores = self.aggregate_boosting()\n",
    "        \n",
    "        sorted_nums = sorted(final_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        combinations_list = []\n",
    "        top_pool = [num for num, score in sorted_nums[:30]]\n",
    "        \n",
    "        for i in range(n):\n",
    "            if i == 0:\n",
    "                combo = [num for num, score in sorted_nums[:self.config.nums_per_draw]]\n",
    "            else:\n",
    "                weights = [final_scores[num] for num in top_pool]\n",
    "                total_w = sum(weights)\n",
    "                probs = [w/total_w for w in weights]\n",
    "                \n",
    "                combo = list(np.random.choice(\n",
    "                    top_pool, \n",
    "                    size=self.config.nums_per_draw, \n",
    "                    replace=False,\n",
    "                    p=probs\n",
    "                ))\n",
    "            \n",
    "            combinations_list.append(sorted(combo))\n",
    "            \n",
    "        return combinations_list\n",
    "    \n",
    "    def display_neural_network_analysis(self):\n",
    "        \"\"\"Affiche une analyse dÃ©taillÃ©e du module rÃ©seau de neurones.\"\"\"\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(f\"{'ğŸ§  ANALYSE RÃ‰SEAU DE NEURONES (VARIANTE 1 - SGD)':^70}\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        # Trouver le module NN\n",
    "        nn_module = None\n",
    "        for m in self.modules:\n",
    "            if isinstance(m, NeuralNetworkModule):\n",
    "                nn_module = m\n",
    "                break\n",
    "        \n",
    "        if nn_module is None:\n",
    "            print(\"Module rÃ©seau de neurones non trouvÃ©.\")\n",
    "            return\n",
    "        \n",
    "        # Afficher les coefficients\n",
    "        print(\"\\nğŸ“Š COEFFICIENTS DES FEATURES:\")\n",
    "        print(f\"   â€¢ DonnÃ©es historiques (coef1): {nn_module.coefficients[0]}\")\n",
    "        print(f\"   â€¢ FrÃ©quence relative (coef2):  {nn_module.coefficients[1]}\")\n",
    "        print(f\"   â€¢ DÃ©jÃ  vu / Ã‰cart (coef3):     {nn_module.coefficients[2]}\")\n",
    "        print(f\"   â€¢ Moyenne mobile (coef4):      {nn_module.coefficients[3]}\")\n",
    "        print(f\"   â€¢ Entropie (coef5):            {nn_module.coefficients[4]}\")\n",
    "        \n",
    "        # Afficher l'architecture\n",
    "        print(\"\\nğŸ—ï¸  ARCHITECTURE DU RÃ‰SEAU:\")\n",
    "        print(f\"   â€¢ Couche d'entrÃ©e:  {self.config.num_max} neurones\")\n",
    "        for i, size in enumerate(nn_module.hidden_layers):\n",
    "            print(f\"   â€¢ Couche cachÃ©e {i+1}: {size} neurones\")\n",
    "        print(f\"   â€¢ Couche de sortie: {self.config.num_max} neurones\")\n",
    "        \n",
    "        # Top prÃ©dictions\n",
    "        print(\"\\nğŸ¯ TOP 20 PRÃ‰DICTIONS DU RÃ‰SEAU DE NEURONES:\")\n",
    "        top20 = nn_module.get_top_numbers(20)\n",
    "        print(f\"   {top20}\")\n",
    "        \n",
    "        # DÃ©tail des scores\n",
    "        print(\"\\nğŸ“ˆ SCORES DÃ‰TAILLÃ‰S (Top 10):\")\n",
    "        sorted_scores = sorted(nn_module.scores.items(), key=lambda x: x[1], reverse=True)[:10]\n",
    "        for num, score in sorted_scores:\n",
    "            bar = \"â–ˆ\" * int(score * 30)\n",
    "            print(f\"   NÂ°{num:2d}: {score:.4f} {bar}\")\n",
    "    \n",
    "    def display_full_analysis(self):\n",
    "        \"\"\"Affiche l'analyse complÃ¨te.\"\"\"\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(f\"{'ğŸ”¬ IA LABO - ANALYSE MULTI-MODÃˆLES':^70}\")\n",
    "        print(f\"{'Jeu: ' + self.config.name:^70}\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        self._compute_all_scores()\n",
    "        \n",
    "        # Top 10 de chaque module\n",
    "        print(\"\\nğŸ“Š TOP 10 PAR MODULE:\")\n",
    "        print(\"-\"*70)\n",
    "        for module in self.modules:\n",
    "            top10 = module.get_top_numbers(10)\n",
    "            print(f\"   {module.name:15} â†’ {top10}\")\n",
    "        \n",
    "        # Analyse dÃ©taillÃ©e du rÃ©seau de neurones\n",
    "        self.display_neural_network_analysis()\n",
    "        \n",
    "        # RÃ©sultats agrÃ©gÃ©s\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"ğŸ“¦ RÃ‰SULTATS AGRÃ‰GÃ‰S\")\n",
    "        print(\"-\"*70)\n",
    "        \n",
    "        bagging_scores = self.aggregate_bagging()\n",
    "        bagging_top = sorted(bagging_scores.items(), key=lambda x: x[1], reverse=True)[:15]\n",
    "        print(f\"\\n   BAGGING (moyenne):    {[num for num, _ in bagging_top]}\")\n",
    "        \n",
    "        boosting_scores = self.aggregate_boosting()\n",
    "        boosting_top = sorted(boosting_scores.items(), key=lambda x: x[1], reverse=True)[:15]\n",
    "        print(f\"   BOOSTING (pondÃ©rÃ©):   {[num for num, _ in boosting_top]}\")\n",
    "        \n",
    "        # Combinaisons suggÃ©rÃ©es\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"ğŸ° COMBINAISONS SUGGÃ‰RÃ‰ES\")\n",
    "        print(\"-\"*70)\n",
    "        \n",
    "        combos = self.generate_combinations(5, method=\"boosting\")\n",
    "        for i, combo in enumerate(combos, 1):\n",
    "            print(f\"   Grille {i}: {combo} (somme: {sum(combo)})\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"=\"*70)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "#                      EXÃ‰CUTION\n",
    "# ============================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"\"\"\n",
    "    â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "    â•‘                                                                  â•‘\n",
    "    â•‘          ğŸ§  IA LABO - VARIANTE 1 (RÃ‰SEAU DE NEURONES) ğŸ§          â•‘\n",
    "    â•‘                    EntrÃ©es PondÃ©rÃ©es + SGD                       â•‘\n",
    "    â•‘                                                                  â•‘\n",
    "    â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "    \"\"\")\n",
    "    \n",
    "    # Configuration (changer pour votre jeu)\n",
    "    config = CONFIGS[\"loto\"]  # ou \"loto\", \"euromillions\"\n",
    "    \n",
    "    try:\n",
    "        lab = IALabo(config)\n",
    "        lab.display_full_analysis()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Erreur: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
